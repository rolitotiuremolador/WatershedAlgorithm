{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a0b481-1a8e-4210-a60b-f3571c89bb89",
   "metadata": {},
   "source": [
    "[SOURCE 32](https://www.youtube.com/watch?v=g3OZJ6skE_U)\n",
    "\n",
    "[practical-machine-learning-and-image-processing-1st-edition.pdf](https://www.globaldevelopment.dk/media/attachments/2021/07/31/practical-machine-learning-and-image-processing-1st-edition.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb8fdb-5ee3-4fbd-a89c-cef106a77cbf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check directory\n",
    "import os\n",
    "cd = os.getcwd()\n",
    "os.listdir(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e113d-dfa3-49b1-b69b-1f438606c670",
   "metadata": {},
   "source": [
    "### Step 1 - Read image and set pixel size\n",
    "*If needed, converts the results into microns, not pixels.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9372dc3c-f76c-47e1-a17b-12a1ed02860b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"thinsection_image2.jpg\")\n",
    "pixels_to_um = 0.5 # 1 pixel = 0.5 um or 500 nm\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "# convert image into grayscale\n",
    "img_g = cv.imread(\"thinsection_image2.jpg\", 0)\n",
    "# or..\n",
    "# img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"Gray\", img_g1)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b2ceb-00cf-41af-9ec9-93ff119add0d",
   "metadata": {},
   "source": [
    "### Step 2 - Denoise, if required, and then threshold image to separate grains from boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fb5727-5bf7-4141-a1c7-6611a1b01270",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# plt.hist(img.flat, bins = 100, range=(0,255))\n",
    "ret, thresh = cv.threshold(img_g1, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "cv.imshow(\"Threshold\", thresh)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc7f96-0e8b-4860-8e09-afc3f5869714",
   "metadata": {},
   "source": [
    "### Step 3 - Clean up image, if needed (erode, etc) and create mask for grains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f225c1-3830-4a23-a1ff-441973f464de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "eroded = cv.erode(thresh, kernel, iterations=1)\n",
    "dilated = cv.dilate(eroded, kernel, iterations=1)\n",
    "\n",
    "# cv.imshow(\"Threshold image\", thresh)\n",
    "# cv.imshow(\"Eroded\", eroded)\n",
    "cv.imshow(\"Dilated\", dilated)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26e8a3d5-2a60-4744-8667-e520e9df7bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "from skimage import io, color, measure\n",
    "\n",
    "# Show the current size of the image\n",
    "h, w = dilated.shape\n",
    "print(h,w)\n",
    "# print(type(img_g))\n",
    "\n",
    "### TO DO: Research on this!\n",
    "mask = eroded == 255\n",
    "# io.imshow(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108daf4-99e6-4734-a9a9-0cb90d13a4fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check image size\n",
    "height, width, channels = img.shape\n",
    "print(height, width, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828b92f-75f3-4079-8640-8aef83565890",
   "metadata": {},
   "source": [
    "### Step 4 - Label grains in the masked image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a08dd14-caf6-4788-aa84-3581d6450721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = [[1,1,1],[1,1,1],[1,1,1]]\n",
    "labeled_mask, num_labels = ndimage.label(mask, structure=s)\n",
    "\n",
    "img2 = color.label2rgb(labeled_mask, bg_label=0)\n",
    "cv.imshow(\"Colored_label\", img2)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c756189-f66d-4163-9a22-d30246acaa79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5\n",
    "clusters = measure.regionprops(labeled_mask, img)\n",
    "\n",
    "for prop in clusters:\n",
    "    print('Label: {} Area: {}'.format(prop.label, prop.area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d792ae79-b19f-4de2-b801-1881b4163e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "propList = ['Area', \n",
    "            'equivalent_diameter',\n",
    "            'orientation',\n",
    "            'MajorAxisLength',\n",
    "            'MinorAxisLength',\n",
    "            'Perimeter',\n",
    "            'MinIntensity',\n",
    "            'MeanIntensity',\n",
    "            'MaxIntensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c249c-133c-49b3-a66c-d12e45a75676",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('image_measurements.csv', 'w')\n",
    "output_file.write((',' + \",\".join(propList) + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19e88a-4224-411a-b729-c7417d3beec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_props in clusters:\n",
    "    output_file.write(str(cluster_props['Label']))\n",
    "    for i, prop in enumerate(propList):\n",
    "        if(prop == 'Area'):\n",
    "            to_print = cluster_props[prop]*pixels_to_um**2\n",
    "        elif(prop == 'orientation'):\n",
    "            to_print = cluster_props[prop]*57.2958\n",
    "        elif(prop.find('Intensity') < 0):\n",
    "            to_print = cluster_props[prop]*pixels_to_um\n",
    "        else:\n",
    "            to_print = cluster_props[prop]\n",
    "            \n",
    "        output_file.write(',' + str(to_print))\n",
    "    output_file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
