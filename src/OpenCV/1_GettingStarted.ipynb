{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58e7159-050a-4109-8a42-8b6985895f25",
   "metadata": {},
   "source": [
    "___\n",
    "## Introduction to OpenCV - Learn the foundation\n",
    "\n",
    "* [Source](https://docs.opencv.org/4.5.2/db/deb/tutorial_display_image.html)\n",
    "* [Source Youtube](https://www.youtube.com/watch?v=oXlwWbU8l2o)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e921d-6f11-48ce-990a-bd7720afc925",
   "metadata": {},
   "source": [
    "### Reading and showing images and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d772e37-cf6e-433b-a633-18b6e80a5051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading and displaying and image\n",
    "import cv2 as cv\n",
    "img = cv.imread(\"water_coins.jpg\")\n",
    "cv.imshow(\"Image\", img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f73229-dce6-4d5c-85f0-c9519a31901f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading videos and playing it\n",
    "import cv2 as cv\n",
    "capture = cv.VideoCapture(\"dog.mp4\")\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    cv.imshow('Dog', frame)\n",
    "    \n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc483b7-c8fb-4f45-a417-8e8433c8779f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rescaling Images and Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b7436-f0ab-43d9-8f30-1ed2abf501de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rescale a video\n",
    "import cv2 as cv\n",
    "\n",
    "# Function to rescale the frame size (NOTE: Can be used for Images, Videos, and Live Video)\n",
    "def rescaleFrame(frame, scale=0.75):\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width, height)\n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)\n",
    "\n",
    "# Function to change resolution (NOTE: Only for live video/capture/frame)\n",
    "def changeRes(width, height):\n",
    "    capture.set(3, width)\n",
    "    capture.set(4, height)\n",
    "\n",
    "\n",
    "# Reading videos and use the create function\n",
    "capture = cv.VideoCapture('dog.mp4')\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    frame_resized = rescaleFrame(frame, scale=.2)\n",
    "    cv.imshow('Dog', frame)\n",
    "    cv.imshow('Dog Resized', frame_resized)\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2210fe-44e9-4940-9ed1-740c006d0ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rescale image\n",
    "\n",
    "def rescaleImg(frame, scale=0.50):\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width, height)\n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = cv.imread('water_coins.jpg')\n",
    "r_img = rescaleImg(img)\n",
    "cv.imshow('Coins', img)\n",
    "cv.imshow('Rescal Coins', r_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d013fec-8cd8-45ee-a2ef-69d1cbcbd5fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drawing Shapes and Putting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccda0a-0283-40a8-ba48-2edf5d71d005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Draw a blank image\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "cv.imshow('Blank', blank)\n",
    "\n",
    "# Paint image with a color\n",
    "# blank[:] = 0,254,201\n",
    "# blank[200:300,300:400] = 0,0,255 #color a range of pixels\n",
    "# cv.imshow(\"Red\", blank)\n",
    "\n",
    "# Draw a rectangle\n",
    "# cv.rectangle(blank, (0,0), (250,250), (0,250,0), thickness=cv.FILLED) # Try cv.FILLED, or -1 in the thickness parameter\n",
    "# cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]//2), (0,255,0), thickness=-1)\n",
    "# cv.imshow(\"Rectangle\", blank)\n",
    "\n",
    "# Draw a circle\n",
    "# cv.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness=2)\n",
    "# cv.imshow(\"Circle\", blank)\n",
    "\n",
    "# # Draw a line\n",
    "# cv.line(blank, (0,0),(blank.shape[1]//2, blank.shape[0]//2), (255,255,255), thickness=3)\n",
    "# cv.imshow(\"Line\", blank)\n",
    "\n",
    "# Write a text\n",
    "cv.putText(blank, 'Hello', (255,255), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2)\n",
    "cv.imshow(\"Text on image\", blank)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0c806-7c18-47ef-a3e1-deb0b51ff3ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5 Essentials Function in OpenCV for Computer Vision - 34:00\n",
    "\n",
    "*Convert to grayscale, Blur, Edge Cascades (Canny), Dilating image, Eroding, Resize, Cropping*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7df109-a848-4a98-a675-fc4d1b626dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('coins1.jpeg')\n",
    "cv.imshow('Original',img)\n",
    "\n",
    "# Convert image into grayscale\n",
    "img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"Gray\", img_g)\n",
    "\n",
    "# Blur\n",
    "# img_b = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "# cv.imshow(\"Blur\", img_b)\n",
    "\n",
    "# # Edge Cascade\n",
    "# img_canny = cv.Canny(img,125, 175)\n",
    "# cv.imshow(\"Canny\", img_canny)\n",
    "\n",
    "# # Dilating the image\n",
    "# img_d = cv.dilate(img_canny, (3,3), iterations=2)\n",
    "# cv.imshow(\"Dilated\", img_d)\n",
    "\n",
    "# # Eroding \n",
    "# img_e = cv.erode(img_d, (7,7), iterations=3)\n",
    "# cv.imshow(\"Eroded\", img_e)\n",
    "\n",
    "# Resize \n",
    "img_r = cv.resize(img, (200,150), interpolation=cv.INTER_AREA) # use INTER_LINEAR or INTER_CUBIC when enlarging image for resize\n",
    "cv.imshow(\"Resized\", img_r)\n",
    "\n",
    "# Cropping\n",
    "img_c = img[10:50, 50:80]\n",
    "cv.imshow(\"Cropped\", img_c)              \n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56560b40-9d89-40ca-87bd-118cbc7406fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Image Transformation 44:15\n",
    "\n",
    "*Translation,*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898b704-ed3a-4a11-8ab8-8c84bbab5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"coins1.jpeg\")\n",
    "cv.imshow(\"Image\", img)\n",
    "\n",
    "# Translation\n",
    "def translate(img, x, y):\n",
    "    transMat = np.float32([[1,0,x], [0,1,y]])\n",
    "    dimensions = (img.shape[1], img.shape[0])\n",
    "    return cv.warpAffine(img, transMat, dimensions)\n",
    "\n",
    "# -x moves the image to the left\n",
    "# -y moves the image up\n",
    "# x moves the image to the right\n",
    "# y moves the image down\n",
    "\n",
    "translatedImg = translate(img, 100, 100)\n",
    "cv.imshow(\"Translated\", translatedImg)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706dda1-600e-48ae-8738-7c971a8005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"coins1.jpeg\")\n",
    "\n",
    "def rotate(img, angle, rotPoint=None):\n",
    "    (height, width) = img.shape[:2]\n",
    "    \n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width, height)\n",
    "    \n",
    "    return cv.warpAffine(img, rotMat, dimensions)\n",
    "\n",
    "# Show original image\n",
    "cv.imshow(\"Original Img\", img)\n",
    "\n",
    "rotatedImg = rotate(img, -10)\n",
    "# cv.imshow(\"Rotated 45\", rotatedImg)\n",
    "\n",
    "# Resizing image\n",
    "resized = cv.resize(img, (300,300), interpolation=cv.INTER_CUBIC)\n",
    "# cv.imshow(\"Resized\", resized)\n",
    "\n",
    "# Flipping the image\n",
    "flip = cv.flip(img,1)\n",
    "# cv.imshow(\"Flipped image\", flip)\n",
    "\n",
    "# Check image size\n",
    "w, h, c, = img.shape\n",
    "print(w,h,c)\n",
    "\n",
    "# Cropping the image\n",
    "cropped = img[2:30, 3:100]\n",
    "cv.imshow(\"Cropped\", cropped)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fef647-cc99-44cf-bf9b-44269fa3149b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Contour Detections 57:07\n",
    "\n",
    "*Contour and Edges are 2 different things*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c3e62-0433-4d3b-a6e0-68a0db46ea94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"coins1.jpeg\")\n",
    "# cv.imshow(\"Original\", img)\n",
    "\n",
    "img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"Gray\", img_g)\n",
    "\n",
    "# Add this portion of blurring the image to see effect on the number of contours found.\n",
    "blur = cv.GaussianBlur(img_g, (5,5), cv.BORDER_DEFAULT)\n",
    "cv.imshow(\"Blur\", blur)\n",
    "\n",
    "\n",
    "# Grab the image detector using the Canny function @ 1:04:15 time\n",
    "img_canny = cv.Canny(blur, 125, 175)\n",
    "cv.imshow(\"Canny Edges\", img_canny)\n",
    "contours, heirarchies = cv.findContours(img_canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contours found!')\n",
    "\n",
    "\n",
    "\n",
    "# Instead of using Canny function to detect and find edges or contour, it can be done using thres..\n",
    "ret, thresh = cv.threshold(img_g, 125, 255, cv.THRESH_BINARY)\n",
    "cv.imshow(\"Thresh\", thresh)\n",
    "\n",
    "# contours, hierarchies = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "# print(f'{len(contours)} contour(s) found!')\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81e41e-5f6b-4276-9c9d-b16825afc9cd",
   "metadata": {},
   "source": [
    "### Advance - Color Spaces @ 1:12:54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e6d1a-6eb8-47d2-bdee-e01a90b49e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# Image resizer function\n",
    "def resizer(frame, scale=0.50):\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimension = (width, height)\n",
    "    return cv.resize(frame, dimension, interpolation=cv.INTER_AREA)\n",
    "    \n",
    "img = resizer(cv.imread(\"apple_600x600.jpg\"))\n",
    "cv.imshow(\"Red Image\", img)\n",
    "\n",
    "# # BGR to Grayscale\n",
    "# img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "# cv.imshow(\"Gray Image\", img_g)\n",
    "\n",
    "# # BGR to HSV\n",
    "# img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "# cv.imshow(\"HSV Image\", img_hsv)\n",
    "\n",
    "# # BGR to LAB\n",
    "# img_lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "# cv.imshow(\"LAB Image\", img_lab)\n",
    "\n",
    "# Images is viewed as RGB outside the OpenCV format (BGR), let us see it\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_p = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9390763-3382-4b29-a8dd-f553b98f459e",
   "metadata": {},
   "source": [
    "### Splitting Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6328a228-8488-40df-8d84-e380528bf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "def resize(frame, scale=0.75):\n",
    "    return cv.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = resize(cv.imread(\"apple_600x600.jpg\"))\n",
    "# cv.imshow(\"Image\", img)\n",
    "\n",
    "# Splitting the color spaces of Red Green and Blue\n",
    "b, g, r = cv.split(img)\n",
    "# cv.imshow(\"Blue\", b)\n",
    "# cv.imshow(\"Green\", g)\n",
    "# cv.imshow(\"Red\", r)\n",
    "\n",
    "# Merge the split color spaces\n",
    "import numpy as np\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "blue = cv.merge([b, blank, blank]) # passing the list of b, blank, blank\n",
    "green = cv.merge([blank,g, blank])\n",
    "red = cv.merge([blank, blank, r])\n",
    "\n",
    "cv.imshow(\"Blue\", blue)\n",
    "cv.imshow(\"Green\", green)\n",
    "cv.imshow(\"Red\", red)\n",
    "\n",
    "# print(img.shape)\n",
    "# print(b.shape)\n",
    "# print(g.shape)\n",
    "# print(r.shape)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0355ba-4d2b-4b0e-b606-59405743f5ab",
   "metadata": {},
   "source": [
    "### Advanced - Blurring Techniques 1:31:05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27bdbbe3-1dfe-47f0-949e-b53b731c1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def rescaler(frame, scale=0.25):\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width, height)\n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = cv.imread(\"apple-red-green-fruit.jpg\")\n",
    "rimg = rescaler(img)\n",
    "cv.imshow(\"Original Image\", rimg)\n",
    "\n",
    "# First method of blurrig -> AVERAGING \n",
    "average = cv.blur(rimg, (7,7)) # change value of blurring kernel size (n, n) to increase/decrease blurring effect\n",
    "cv.imshow(\"Average Blur\", average)\n",
    "\n",
    "# 2nd function - GAUSSIAN BLUR\n",
    "gauss = cv.GaussianBlur(rimg, (7,7), 0)\n",
    "cv.imshow(\"Gauss Blur\", gauss)\n",
    "\n",
    "# 3rd function - MEDIAN BLUR\n",
    "median = cv.medianBlur(rimg, 7)\n",
    "cv.imshow(\"Median blur\", median)\n",
    "\n",
    "# Bilateral Blur\n",
    "bilateral = cv.bilateralFilter(rimg, 5, 15, 15)\n",
    "cv.imshow(\"Bilateral\", bilateral)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af1b8e-66f9-4a06-9f3e-0500c9945799",
   "metadata": {},
   "source": [
    "### Advanced - BITWISE OPERATORS @ 1:44:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5c1ce7-299f-443e-931f-7d1ad8bae939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "blank = np.zeros((400,400), dtype=\"uint8\")\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "circle = cv.circle(blank.copy(), (200,200), 200, 255, -1)\n",
    "\n",
    "cv.imshow(\"Rec\", rectangle)\n",
    "cv.imshow(\"Circle\", circle)\n",
    "\n",
    "# User bitwise operator for our image\n",
    "\n",
    "# Bitwise AND --> show the intersecting region\n",
    "bw_and = cv.bitwise_and(rectangle, circle)\n",
    "cv.imshow(\"BW AND\", bw_and)\n",
    "\n",
    "# Bitwise OR -- show intersecting and non-intersecting\n",
    "bw_or = cv.bitwise_or(rectangle, circle)\n",
    "cv.imshow(\"BW OR\", bw_or)\n",
    "\n",
    "# Bitwise XOR -- show non-intersecting regions\n",
    "bw_xor = cv.bitwise_xor(rectangle, circle)\n",
    "cv.imshow(\"BW XOR\", bw_xor)\n",
    "\n",
    "# Bitwise NOT\n",
    "bw_not = cv.bitwise_not(rectangle)\n",
    "cv.imshow(\"BW NOT\", bw_not)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f825e-d66d-4f07-9a93-27caebbda0c6",
   "metadata": {},
   "source": [
    "### Advanced - MASKING @ 1:53:07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8deb9cc4-b0ec-4a08-a4dd-9bf7a478ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def resizeImg(frame, scale=0.50):\n",
    "    return cv.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = resizeImg(cv.imread(\"apple-red-green-fruit.jpg\"))\n",
    "cv.imshow(\"Image\", img)\n",
    "\n",
    "# Create a blank/kernel (must be same as the image size)\n",
    "blank = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "cv.imshow(\"Blank\", blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2, img.shape[0]//2), 100, 255, -1)\n",
    "# cv.imshow(\"Mask\", circle)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (126, 48), (231,231), 255, -1)\n",
    "# cv.imshow(\"Rectangle\", rectangle)\n",
    "\n",
    "# masked_img = cv.bitwise_and(img, img, mask=circle)\n",
    "# cv.imshow(\"Maskeid Image\", masked_img)\n",
    "\n",
    "# Make a weird mask\n",
    "# rectangle = cv.rectangle(blank.copy(), (126, 48), (231,231), 255, -1)\n",
    "weird_mask = cv.bitwise_and(rectangle, circle)\n",
    "cv.imshow(\"Weird mask\", weird_mask)\n",
    "\n",
    "# use weird shape as mask\n",
    "masked_img = cv.bitwise_and(img, img, mask=weird_mask)\n",
    "cv.imshow(\"Maskeid Image\", masked_img)\n",
    "\n",
    "# w, h, c = img.shape\n",
    "# print(w,h,c)\n",
    "# print(img.shape[0]//2)\n",
    "# print(img.shape[1]//2)\n",
    "# print(blank.shape)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef5f7a-5ec0-4988-a553-9f8857bff953",
   "metadata": {},
   "source": [
    "### Advanced - Computing Histograms @ 2:01:42\n",
    "\n",
    "Histogram allows us to view the distribution of pixel intensity in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ebede59-723f-4999-b15f-61adc1a13cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "def resizeImg(frame, scale=0.50):\n",
    "    return cv.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv.INTER_AREA)\n",
    "\n",
    "img = resizeImg(cv.imread(\"apple-red-green-fruit.jpg\"))\n",
    "cv.imshow(\"Image\", img)\n",
    "\n",
    "img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"Gray Image\", img_g)\n",
    "\n",
    "# Lets create a mask\n",
    "import numpy as np\n",
    "blank = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "circle = cv.circle(blank, (img.shape[1]//2, img.shape[0]//2), 100, 255, -1)\n",
    "# cv.imshow(\"Circle\", circle)\n",
    "mask = cv.bitwise_and(img_g, img_g, mask=circle)\n",
    "cv.imshow(\"Mask\", mask)\n",
    "\n",
    "# Grayscale histogram\n",
    "# hist_gray = cv.calcHist([img_g], [0], None, [256], [0,256]) # without mask\n",
    "# hist_gray = cv.calcHist([img_g], [0], mask, [256], [0,256]) # with mask\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.title(\"Grayscale Hist\")\n",
    "# plt.xlabel(\"Bins\")\n",
    "# plt.ylabel(\"# of pixels\")\n",
    "# plt.plot(hist_gray)\n",
    "# plt.xlim([0,256])\n",
    "# plt.show()\n",
    "\n",
    "# Compute for color histogram @ 2:10:05\n",
    "# colors = ('b', 'g', 'r')\n",
    "# for i, col in enumerate(colors):\n",
    "#     hist = cv.calcHist([img], [i], None, [256], [0, 256])\n",
    "#     plt.plot(hist, color=col)\n",
    "#     plt.xlim([0,256])\n",
    "    \n",
    "# plt.show()\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88a785-2b99-425d-9bdf-b4d10488e7c5",
   "metadata": {},
   "source": [
    "### Advanced - Thresholding\n",
    "Thresholding is simply a binarization of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b9de4ea-6d9f-4431-b2d0-54dad1fa7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import cv2 as cv\n",
    "\n",
    "    def resizeImg(frame, scale=0.50):\n",
    "        return cv.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv.INTER_AREA)\n",
    "\n",
    "    img = resizeImg(cv.imread(\"apple-red-green-fruit.jpg\"))\n",
    "    cv.imshow(\"Image\", img)\n",
    "\n",
    "    img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow(\"Gray Image\", img_g)\n",
    "\n",
    "# Simple thresholding\n",
    "ret, thresh = cv.threshold(img_g, 150, 255, cv.THRESH_BINARY)\n",
    "cv.imshow(\"Threshold\", thresh)\n",
    "\n",
    "ret, thresh_inv = cv.threshold(img_g, 150, 255, cv.THRESH_BINARY_INV)\n",
    "cv.imshow(\"Threshold Inverse\", thresh_inv)\n",
    "\n",
    "# Adaptive Thresholding (letting computer set thresholding itself)\n",
    "adaptive_thresh = cv.adaptiveThreshold(img_g, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 11, 3)\n",
    "cv.imshow(\"Adaptive Thresh\", adaptive_thresh)\n",
    "\n",
    "# Instead of _MEAN, let us use GAUSSIAN\n",
    "adaptive_thresh = cv.adaptiveThreshold(img_g, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 3)\n",
    "cv.imshow(\"Adaptive Thresh Gaussian\", adaptive_thresh)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ad44a-2bac-4790-9f40-410dd67cb7fb",
   "metadata": {},
   "source": [
    "### Advanced - Edge Detection @ 2:26:29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6f5fa-bfd3-4131-a822-37130ba49a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "def resizeImg(frame, scale=0.50):\n",
    "    return cv.resize(frame, (int(frame.shape[1]*scale), int(frame.shape[0]*scale)), interpolation=cv.INTER_AREA)\n",
    "\n",
    "# img = resizeImg(cv.imread(\"apple-red-green-fruit.jpg\"))\n",
    "img = resizeImg(cv.imread(\"apple_600x600.jpg\"))\n",
    "cv.imshow(\"Image\", img)\n",
    "\n",
    "img_g = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow(\"Gray Image\", img_g)\n",
    "\n",
    "# Laplician method\n",
    "import numpy as np\n",
    "lap = cv.Laplacian(img_g, cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv.imshow(\"Laplacian\", lap)\n",
    "\n",
    "# Sobel\n",
    "sobelx = cv.Sobel(img_g, cv.CV_64F, 1, 0)\n",
    "sobely = cv.Sobel(img_g, cv.CV_64F, 0, 1)\n",
    "cv.imshow(\"Sobel X\", sobelx)\n",
    "cv.imshow(\"Sobel Y\", sobely)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
